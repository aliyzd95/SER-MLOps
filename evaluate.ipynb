{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T13:47:58.539779Z",
     "start_time": "2025-06-06T13:47:58.446984Z"
    }
   },
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "else:\n",
    "    print(gpu_info)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun  6 17:17:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.28                 Driver Version: 576.28         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   62C    P8             17W /   80W |     508MiB /   8192MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2052    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7396    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A           10168    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           11360    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           12016    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           12836    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13696    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           14804    C+G   ...mba6cd70vzyy\\ArmouryCrate.exe      N/A      |\n",
      "|    0   N/A  N/A           15392    C+G   ...ekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A           16464    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           16888    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17296    C+G   ...2025.1\\jbr\\bin\\cef_server.exe      N/A      |\n",
      "|    0   N/A  N/A           17436    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:03.355110Z",
     "start_time": "2025-06-06T13:47:58.586693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, Audio, concatenate_datasets, DatasetDict\n",
    "import os\n",
    "\n",
    "clips_dir = \"D:/projects/SPEECH/cv-corpus-21.0-2025-03-14/fa/clips\"\n",
    "data_files = {\n",
    "    \"train\": \"D:/projects/SPEECH/cv-corpus-21.0-2025-03-14/fa/train.csv\",\n",
    "    \"test\": \"D:/projects/SPEECH/cv-corpus-21.0-2025-03-14/fa/test.csv\",\n",
    "    \"validation\": \"D:/projects/SPEECH/cv-corpus-21.0-2025-03-14/fa/dev.csv\"\n",
    "}\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "\n",
    "def add_full_path(example):\n",
    "    example[\"path\"] = os.path.join(clips_dir, example[\"path\"])\n",
    "    return example\n",
    "\n",
    "\n",
    "dataset = dataset.map(add_full_path)\n",
    "\n",
    "dataset = dataset.cast_column(\"path\", Audio(sampling_rate=16000))\n",
    "\n",
    "for split in dataset:\n",
    "    dataset[split] = dataset[split].rename_columns({\n",
    "        \"path\": \"audio\",\n",
    "        \"sentence\": \"text\"\n",
    "    })\n",
    "\n",
    "for split in dataset:\n",
    "    dataset[split] = dataset[split].remove_columns(\n",
    "        [col for col in dataset[split].column_names if col not in [\"audio\", \"text\"]]\n",
    "    )\n",
    "\n",
    "train_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"validation\"]])\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = train_dataset\n",
    "common_voice[\"test\"] = test_dataset\n",
    "\n",
    "print(common_voice)"
   ],
   "id": "b1732ac31fe9a796",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 40397\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 10668\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:03.761603Z",
     "start_time": "2025-06-06T13:48:03.758402Z"
    }
   },
   "cell_type": "code",
   "source": "checkpoint_path = \"whisper-small-persian-v1/checkpoint-7575\"",
   "id": "741a8a02cce59b0a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:17.173251Z",
     "start_time": "2025-06-06T13:48:03.780297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(checkpoint_path)"
   ],
   "id": "ea72589ad71bc3aa",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:18.251454Z",
     "start_time": "2025-06-06T13:48:17.190319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Persian\", task=\"transcribe\")"
   ],
   "id": "ad811938491c2fdb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:22.821917Z",
     "start_time": "2025-06-06T13:48:18.628653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Persian\", task=\"transcribe\")"
   ],
   "id": "4efb2a8c4c7b088e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:23.046270Z",
     "start_time": "2025-06-06T13:48:23.033914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ],
   "id": "273ea3567a3a8f85",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:23.223460Z",
     "start_time": "2025-06-06T13:48:23.219313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch"
   ],
   "id": "81a30ccdff34b7bc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:32.740721Z",
     "start_time": "2025-06-06T13:48:23.405428Z"
    }
   },
   "cell_type": "code",
   "source": "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"])",
   "id": "c9bc68113ec076bf",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:39.673029Z",
     "start_time": "2025-06-06T13:48:33.593131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(checkpoint_path)"
   ],
   "id": "242cf5bc760b9cc7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:40.082412Z",
     "start_time": "2025-06-06T13:48:40.073662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ],
   "id": "1b6e10bb7eaaab9d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:40.521760Z",
     "start_time": "2025-06-06T13:48:40.509407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ],
   "id": "218bc3823e7a386",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:43.576409Z",
     "start_time": "2025-06-06T13:48:41.415654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ],
   "id": "e836e744a62aed77",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:46.614745Z",
     "start_time": "2025-06-06T13:48:46.604914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ],
   "id": "3b0f597129697740",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:48:49.493239Z",
     "start_time": "2025-06-06T13:48:49.037295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-persian-v1\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,  # increase by 2x for every 2x decrease in batch size\n",
    "    # group_by_length=True,\n",
    "    learning_rate=4e-5,\n",
    "    warmup_steps=500,\n",
    "    # max_steps=4000,\n",
    "    num_train_epochs=3,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    # eval_strategy=\"steps\",\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    # generation_max_length=48,\n",
    "    save_steps=1000,\n",
    "    # eval_steps=1000,\n",
    "    logging_steps=50,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=False,\n",
    "    # load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"wer\",\n",
    "    # greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    "    resume_from_checkpoint='last-checkpoint',\n",
    ")"
   ],
   "id": "434f5486369f6d4e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T12:03:14.908022Z",
     "start_time": "2025-06-06T12:03:13.273318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Seq2SeqTrainer, EarlyStoppingCallback\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    # callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ],
   "id": "9e1d01739790b0e8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A L I\\AppData\\Local\\Temp\\ipykernel_1940\\3731876365.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T13:21:11.814441Z",
     "start_time": "2025-06-06T12:03:15.609137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trainer.args.per_device_eval_batch_size = 8\n",
    "trainer.evaluate()"
   ],
   "id": "fb3f9406651965db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.33234187960624695,\n",
       " 'eval_model_preparation_time': 0.0,\n",
       " 'eval_wer': 31.930087051142547,\n",
       " 'eval_runtime': 4676.1764,\n",
       " 'eval_samples_per_second': 2.281,\n",
       " 'eval_steps_per_second': 0.285}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:04:23.633533Z",
     "start_time": "2025-06-06T17:04:23.614934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ],
   "id": "55b7d1f5d03d13b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1db4228fed8e4527a2018e4f56099e1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:05:12.518189Z",
     "start_time": "2025-06-06T17:04:31.055497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.push_to_hub(\"aliyzd95/whisper-small-persian-v1\")\n",
    "processor.push_to_hub(\"aliyzd95/whisper-small-persian-v1\")"
   ],
   "id": "7c986ea745bd307a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8716260305574ef58082b6be91a179bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\A L I\\.cache\\huggingface\\hub\\models--aliyzd95--whisper-small-persian-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/aliyzd95/whisper-small-persian-v1/commit/bc099dbff80b84dc2c178947ab686a9265413586', commit_message='Upload processor', commit_description='', oid='bc099dbff80b84dc2c178947ab686a9265413586', pr_url=None, repo_url=RepoUrl('https://huggingface.co/aliyzd95/whisper-small-persian-v1', endpoint='https://huggingface.co', repo_type='model', repo_id='aliyzd95/whisper-small-persian-v1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
